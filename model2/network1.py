import torch
import torch.nn as nn
import torch.nn.functional as F


# first model

class Net(nn.Module):
    def __init__(self):
        super(Net, self).__init__()
        # Input image size : 28x28

        # Convolution Layer 1 - Output Size - 28
        self.conv1 = nn.Sequential(
            nn.Conv2d(1, 10, kernel_size=3, padding=1, bias=False), # Input Channels - 1, Output Channels - 12
            nn.BatchNorm2d(10),
            nn.Dropout(0.1),
            nn.ReLU()
        )
        
        # Convolution Layer 2 - Output Size - 28
        self.conv2 = nn.Sequential(
            nn.Conv2d(10, 16, kernel_size=3, padding=1, bias=False),
            nn.BatchNorm2d(16),
            nn.Dropout(0.1),
            nn.ReLU()
        )
        
        # Transition Layer 1 - MaxPool and 1x1 conv - Output Size - 14
        self.transition1 = nn.Sequential(
            nn.MaxPool2d(2, 2),
            nn.Conv2d(16, 10, kernel_size=1, padding=0, bias=False),
        )

        # Convolution Layer 3 - Output Size - 14
        self.conv3 = nn.Sequential(
            nn.Conv2d(10, 16, kernel_size=3, padding=1, bias=False),
            nn.BatchNorm2d(16),
            nn.Dropout(0.1),
            nn.ReLU()
        )

        # Convolution Layer 4 - Output Size - 14
        self.conv4 = nn.Sequential(
            nn.Conv2d(16, 16, kernel_size=3, padding=1, bias=False),
            nn.BatchNorm2d(16),
            nn.Dropout(0.1),
            nn.ReLU()
        )

        # Transition Layer 2 - MaxPool and 1x1 conv - Output Size - 7
        self.transition2 = nn.Sequential(
            nn.MaxPool2d(2, 2),
            nn.Conv2d(16, 10, kernel_size=1, padding=0, bias=False),
        )
        
        # Convolution Layer 5 - Output Size - 7
        self.conv5 = nn.Sequential(
            nn.Conv2d(10, 16, kernel_size=3, padding=1, bias=False),
            nn.BatchNorm2d(16),
            nn.Dropout(0.1),
            nn.ReLU()
        )

        # Convolution Layer 6 - Output Size - 5
        self.conv6 = nn.Sequential(
            nn.Conv2d(16, 10, kernel_size=3, padding=0, bias=False),
            nn.BatchNorm2d(10),
            nn.Dropout(0.1),
            nn.ReLU()
        )
        
        self.gap = nn.AdaptiveAvgPool2d(1)


    def forward(self, x):
        x = self.conv1(x)
        x = self.conv2(x)
        x = self.transition1(x)

        x = self.conv3(x)
        x = self.conv4(x)
        x = self.transition2(x)

        x = self.conv5(x)
        x = self.conv6(x)

        x = self.gap(x)
        x = x.view(-1, 10) 
        return F.log_softmax(x, dim=-1)


'''
(era3_assignments) sravan@sravan-latitude-3410 ~/Personal/Courses/ERA3/Assignment7/ERAV3_Assignment7/model2 (main)$ python train.py 
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 10, 28, 28]             100
       BatchNorm2d-2           [-1, 10, 28, 28]              20
           Dropout-3           [-1, 10, 28, 28]               0
              ReLU-4           [-1, 10, 28, 28]               0
            Conv2d-5           [-1, 16, 28, 28]           1,456
       BatchNorm2d-6           [-1, 16, 28, 28]              32
           Dropout-7           [-1, 16, 28, 28]               0
              ReLU-8           [-1, 16, 28, 28]               0
         MaxPool2d-9           [-1, 16, 14, 14]               0
           Conv2d-10           [-1, 10, 14, 14]             170
           Conv2d-11           [-1, 16, 14, 14]           1,456
      BatchNorm2d-12           [-1, 16, 14, 14]              32
          Dropout-13           [-1, 16, 14, 14]               0
             ReLU-14           [-1, 16, 14, 14]               0
           Conv2d-15           [-1, 16, 14, 14]           2,320
      BatchNorm2d-16           [-1, 16, 14, 14]              32
          Dropout-17           [-1, 16, 14, 14]               0
             ReLU-18           [-1, 16, 14, 14]               0
        MaxPool2d-19             [-1, 16, 7, 7]               0
           Conv2d-20             [-1, 10, 7, 7]             170
           Conv2d-21             [-1, 16, 7, 7]           1,456
      BatchNorm2d-22             [-1, 16, 7, 7]              32
          Dropout-23             [-1, 16, 7, 7]               0
             ReLU-24             [-1, 16, 7, 7]               0
           Conv2d-25             [-1, 10, 5, 5]           1,450
      BatchNorm2d-26             [-1, 10, 5, 5]              20
          Dropout-27             [-1, 10, 5, 5]               0
             ReLU-28             [-1, 10, 5, 5]               0
AdaptiveAvgPool2d-29             [-1, 10, 1, 1]               0
================================================================
Total params: 8,746
Trainable params: 8,746
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 0.89
Params size (MB): 0.03
Estimated Total Size (MB): 0.93
----------------------------------------------------------------
--------------------------------------------
EPOCH: 0
Loss=0.21810711920261383 Batch_id=468 Accuracy=88.03: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 469/469 [00:44<00:00, 10.53it/s]

Training set: Average loss: 0.2181, Accuracy: 52815/60000 (88.03%)


Test set: Average loss: 0.2046, Accuracy: 9654/10000 (96.54%)

--------------------------------------------
--------------------------------------------
EPOCH: 1
Loss=0.13134022057056427 Batch_id=468 Accuracy=96.83: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 469/469 [00:44<00:00, 10.52it/s]

Training set: Average loss: 0.1313, Accuracy: 58100/60000 (96.83%)


Test set: Average loss: 0.1344, Accuracy: 9731/10000 (97.31%)

--------------------------------------------
--------------------------------------------
EPOCH: 2
Loss=0.08379882574081421 Batch_id=468 Accuracy=97.51: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 469/469 [00:45<00:00, 10.35it/s]

Training set: Average loss: 0.0838, Accuracy: 58508/60000 (97.51%)


Test set: Average loss: 0.1077, Accuracy: 9756/10000 (97.56%)

--------------------------------------------
--------------------------------------------
EPOCH: 3
Loss=0.052058104425668716 Batch_id=468 Accuracy=97.86: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 469/469 [00:44<00:00, 10.52it/s]

Training set: Average loss: 0.0521, Accuracy: 58717/60000 (97.86%)


Test set: Average loss: 0.0879, Accuracy: 9784/10000 (97.84%)

--------------------------------------------
--------------------------------------------
EPOCH: 4
Loss=0.06354964524507523 Batch_id=468 Accuracy=98.06: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 469/469 [00:54<00:00,  8.64it/s]

Training set: Average loss: 0.0635, Accuracy: 58837/60000 (98.06%)


Test set: Average loss: 0.0608, Accuracy: 9848/10000 (98.48%)

--------------------------------------------
--------------------------------------------
EPOCH: 5
Loss=0.0334077887237072 Batch_id=468 Accuracy=98.14: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 469/469 [00:50<00:00,  9.31it/s]

Training set: Average loss: 0.0334, Accuracy: 58886/60000 (98.14%)


Test set: Average loss: 0.0523, Accuracy: 9870/10000 (98.70%)

--------------------------------------------
--------------------------------------------
EPOCH: 6
Loss=0.03542369231581688 Batch_id=468 Accuracy=98.29: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 469/469 [00:45<00:00, 10.29it/s]

Training set: Average loss: 0.0354, Accuracy: 58976/60000 (98.29%)


Test set: Average loss: 0.0590, Accuracy: 9850/10000 (98.50%)

--------------------------------------------
--------------------------------------------
EPOCH: 7
Loss=0.11026784777641296 Batch_id=468 Accuracy=98.36: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 469/469 [00:45<00:00, 10.30it/s]

Training set: Average loss: 0.1103, Accuracy: 59017/60000 (98.36%)


Test set: Average loss: 0.0792, Accuracy: 9780/10000 (97.80%)

--------------------------------------------
--------------------------------------------
EPOCH: 8
Loss=0.06673204898834229 Batch_id=468 Accuracy=98.44: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 469/469 [00:46<00:00, 10.06it/s]

Training set: Average loss: 0.0667, Accuracy: 59066/60000 (98.44%)


Test set: Average loss: 0.0497, Accuracy: 9860/10000 (98.60%)

--------------------------------------------
--------------------------------------------
EPOCH: 9
Loss=0.053780317306518555 Batch_id=468 Accuracy=98.51: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 469/469 [00:45<00:00, 10.31it/s]

Training set: Average loss: 0.0538, Accuracy: 59108/60000 (98.51%)


Test set: Average loss: 0.0494, Accuracy: 9871/10000 (98.71%)

--------------------------------------------
--------------------------------------------
EPOCH: 10
Loss=0.12848584353923798 Batch_id=119 Accuracy=98.50:  26%|████████████████████████████▏                                                                                 | 120/469 [00:11<00:34, 10.15it/s]Loss=0.06969179213047028 Batch_id=468 Accuracy=98.53: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 469/469 [00:45<00:00, 10.40it/s]

Training set: Average loss: 0.0697, Accuracy: 59118/60000 (98.53%)


Test set: Average loss: 0.0418, Accuracy: 9894/10000 (98.94%)

--------------------------------------------
--------------------------------------------
EPOCH: 11
Loss=0.03342430293560028 Batch_id=468 Accuracy=98.61: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 469/469 [00:46<00:00, 10.15it/s]

Training set: Average loss: 0.0334, Accuracy: 59169/60000 (98.61%)


Test set: Average loss: 0.0527, Accuracy: 9856/10000 (98.56%)

--------------------------------------------
--------------------------------------------
EPOCH: 12
Loss=0.046446751803159714 Batch_id=468 Accuracy=98.72: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 469/469 [00:45<00:00, 10.23it/s]

Training set: Average loss: 0.0464, Accuracy: 59231/60000 (98.72%)


Test set: Average loss: 0.0451, Accuracy: 9871/10000 (98.71%)

--------------------------------------------
--------------------------------------------
EPOCH: 13
Loss=0.04110344499349594 Batch_id=468 Accuracy=98.61: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 469/469 [00:44<00:00, 10.48it/s]

Training set: Average loss: 0.0411, Accuracy: 59166/60000 (98.61%)


Test set: Average loss: 0.0446, Accuracy: 9874/10000 (98.74%)

--------------------------------------------
--------------------------------------------
EPOCH: 14
Loss=0.03182080760598183 Batch_id=468 Accuracy=98.74: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 469/469 [00:45<00:00, 10.25it/s]

Training set: Average loss: 0.0318, Accuracy: 59243/60000 (98.74%)


Test set: Average loss: 0.0380, Accuracy: 9899/10000 (98.99%)

--------------------------------------------
--------------------------------------------
EPOCH: 15
Loss=0.030829032883048058 Batch_id=468 Accuracy=98.75: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 469/469 [00:47<00:00,  9.80it/s]

Training set: Average loss: 0.0308, Accuracy: 59253/60000 (98.75%)


Test set: Average loss: 0.0420, Accuracy: 9884/10000 (98.84%)

--------------------------------------------
--------------------------------------------
EPOCH: 16
Loss=0.018331298604607582 Batch_id=468 Accuracy=98.74: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 469/469 [00:54<00:00,  8.67it/s]

Training set: Average loss: 0.0183, Accuracy: 59243/60000 (98.74%)


Test set: Average loss: 0.0432, Accuracy: 9880/10000 (98.80%)

--------------------------------------------
--------------------------------------------
EPOCH: 17
Loss=0.02220892906188965 Batch_id=468 Accuracy=98.84: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 469/469 [00:52<00:00,  9.01it/s]

Training set: Average loss: 0.0222, Accuracy: 59305/60000 (98.84%)


Test set: Average loss: 0.0434, Accuracy: 9876/10000 (98.76%)

--------------------------------------------
--------------------------------------------
EPOCH: 18
Loss=0.12251141667366028 Batch_id=468 Accuracy=98.86: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 469/469 [00:56<00:00,  8.26it/s]

Training set: Average loss: 0.1225, Accuracy: 59318/60000 (98.86%)


Test set: Average loss: 0.0375, Accuracy: 9894/10000 (98.94%)

--------------------------------------------
--------------------------------------------
EPOCH: 19
Loss=0.08615144342184067 Batch_id=468 Accuracy=98.75: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 469/469 [00:49<00:00,  9.42it/s]

Training set: Average loss: 0.0862, Accuracy: 59247/60000 (98.75%)


Test set: Average loss: 0.0387, Accuracy: 9897/10000 (98.97%)

--------------------------------------------
'''