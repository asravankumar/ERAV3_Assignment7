# ERAV3_Assignment7: model-3 - *final model*


### Model Summary
```
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 10, 26, 26]              90
              ReLU-2           [-1, 10, 26, 26]               0
       BatchNorm2d-3           [-1, 10, 26, 26]              20
           Dropout-4           [-1, 10, 26, 26]               0
            Conv2d-5           [-1, 16, 24, 24]           1,440
              ReLU-6           [-1, 16, 24, 24]               0
       BatchNorm2d-7           [-1, 16, 24, 24]              32
           Dropout-8           [-1, 16, 24, 24]               0
            Conv2d-9            [-1, 8, 22, 22]           1,152
             ReLU-10            [-1, 8, 22, 22]               0
      BatchNorm2d-11            [-1, 8, 22, 22]              16
          Dropout-12            [-1, 8, 22, 22]               0
        MaxPool2d-13            [-1, 8, 11, 11]               0
           Conv2d-14             [-1, 16, 9, 9]           1,152
             ReLU-15             [-1, 16, 9, 9]               0
      BatchNorm2d-16             [-1, 16, 9, 9]              32
          Dropout-17             [-1, 16, 9, 9]               0
           Conv2d-18             [-1, 16, 7, 7]           2,304
             ReLU-19             [-1, 16, 7, 7]               0
      BatchNorm2d-20             [-1, 16, 7, 7]              32
          Dropout-21             [-1, 16, 7, 7]               0
           Conv2d-22             [-1, 10, 5, 5]           1,440
             ReLU-23             [-1, 10, 5, 5]               0
      BatchNorm2d-24             [-1, 10, 5, 5]              20
          Dropout-25             [-1, 10, 5, 5]               0
AdaptiveAvgPool2d-26             [-1, 10, 1, 1]               0
           Conv2d-27             [-1, 10, 1, 1]             100
================================================================
Total params: 7,830
Trainable params: 7,830
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 0.68
Params size (MB): 0.03
Estimated Total Size (MB): 0.72
----------------------------------------------------------------
```

### Model Input Sizes, Output Sizes and Receptive Field Computation
```
# Layer-wise Analysis of the Neural Network
| Layer              | Input Size | Output Size | Input Channels | Output Channels | Kernel Size | Stride | Padding | Receptive Field |
|---------------------|------------|-------------|----------------|-----------------|-------------|--------|---------|----------------|
| Input              | 28x28      | 28x28       | 1              | 1               | -           | -      | -       | 1              |
| Conv1 + ReLU + BN  | 28x28      | 26x26       | 1              | 10              | 3x3         | 1      | 0       | 3              |
| Conv2 + ReLU + BN  | 26x26      | 24x24       | 10             | 16              | 3x3         | 1      | 0       | 5              |
| Conv3 + ReLU + BN  | 24x24      | 22x22       | 16             | 8               | 3x3         | 1      | 0       | 7              |
| MaxPool (Transition1) | 22x22   | 11x11       | 8              | 8               | 2x2         | 2      | 0       | 8              |
| Conv4 + ReLU + BN  | 11x11      | 9x9         | 8              | 16              | 3x3         | 1      | 0       | 12             |
| Conv5 + ReLU + BN  | 9x9        | 7x7         | 16             | 16              | 3x3         | 1      | 0       | 16             |
| Conv6 + ReLU + BN  | 7x7        | 5x5         | 16             | 10              | 3x3         | 1      | 0       | 20             |
| GAP                | 5x5        | 1x1         | 10             | 10              | 5x5         | -      | -       | 28             |
| Conv7              | 1x1        | 1x1         | 10             | 10              | 1x1         | 1      | 0       | 28             |
```


### Target:
  1. Under 8000 parameters and under 15 epochs, consistently reach test accuracy of 99.4% at least three times.

### Results:
  1. Parameters: 7,830
  2. Best Train Accuracy within epoch 15: 99.21% (epoch 15)
  3. Best Test Accuracy within epoch 15: 99.45% (epoch 13)
  4. Reached 99.40% at epoch 9 and at epoch 12, 13, 14 were 99.40%, 99.45% and 99.43% respectively.

### Analysis:
  1. Upon adding image augmentation, the model was further underfitting now.
  2. Modified the number of channels in each layer multiple times, played with different learning rates but finally found that at almost every network with number of parameters ranging from 7500 to 8000, at epoch 7, 8, 9, 10 it reaches test accuracy of 99.30-99.40 but after that it does not improve significantly.
  3. Finally, with a simple StepLR scheduler and after 8th epoch, the lr got updated and it reached the desired test accuracies(>= 99.40%) consistently.
  4. A scheduler would have yielded the expected result with the previous version of model itself.   



### Training Logs
```
--------------------------------------------
EPOCH: 0
Learning Rate = 0.010000
Loss=0.1989177018404007 Batch_id=468 Accuracy=86.84: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 469/469 [00:55<00:00,  8.51it/s]

Training set: Average loss: 0.1989, Accuracy: 52104/60000 (86.84%)


Test set: Average loss: 0.0799, Accuracy: 9807/10000 (98.07%)

--------------------------------------------
--------------------------------------------
EPOCH: 1
Learning Rate = 0.010000
Loss=0.05726264417171478 Batch_id=468 Accuracy=97.80: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 469/469 [01:04<00:00,  7.25it/s]

Training set: Average loss: 0.0573, Accuracy: 58678/60000 (97.80%)


Test set: Average loss: 0.0462, Accuracy: 9879/10000 (98.79%)

--------------------------------------------
--------------------------------------------
EPOCH: 2
Learning Rate = 0.010000
Loss=0.027088433504104614 Batch_id=468 Accuracy=98.27: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 469/469 [00:56<00:00,  8.23it/s]

Training set: Average loss: 0.0271, Accuracy: 58959/60000 (98.27%)


Test set: Average loss: 0.0380, Accuracy: 9885/10000 (98.85%)

--------------------------------------------
--------------------------------------------
EPOCH: 3
Learning Rate = 0.010000
Loss=0.028176499530673027 Batch_id=468 Accuracy=98.48: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 469/469 [01:03<00:00,  7.39it/s]

Training set: Average loss: 0.0282, Accuracy: 59088/60000 (98.48%)


Test set: Average loss: 0.0293, Accuracy: 9910/10000 (99.10%)

--------------------------------------------
--------------------------------------------
EPOCH: 4
Learning Rate = 0.010000
Loss=0.08518072962760925 Batch_id=468 Accuracy=98.58: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 469/469 [01:08<00:00,  6.88it/s]

Training set: Average loss: 0.0852, Accuracy: 59148/60000 (98.58%)


Test set: Average loss: 0.0316, Accuracy: 9911/10000 (99.11%)

--------------------------------------------
--------------------------------------------
EPOCH: 5
Learning Rate = 0.010000
Loss=0.012765870429575443 Batch_id=468 Accuracy=98.65: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 469/469 [00:59<00:00,  7.94it/s]

Training set: Average loss: 0.0128, Accuracy: 59192/60000 (98.65%)


Test set: Average loss: 0.0264, Accuracy: 9924/10000 (99.24%)

--------------------------------------------
--------------------------------------------
EPOCH: 6
Learning Rate = 0.010000
Loss=0.012400330044329166 Batch_id=468 Accuracy=98.81: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 469/469 [00:59<00:00,  7.90it/s]

Training set: Average loss: 0.0124, Accuracy: 59285/60000 (98.81%)


Test set: Average loss: 0.0228, Accuracy: 9933/10000 (99.33%)

--------------------------------------------
--------------------------------------------
EPOCH: 7
Learning Rate = 0.010000
Loss=0.05124722421169281 Batch_id=468 Accuracy=98.89: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 469/469 [00:56<00:00,  8.29it/s]

Training set: Average loss: 0.0512, Accuracy: 59332/60000 (98.89%)


Test set: Average loss: 0.0236, Accuracy: 9932/10000 (99.32%)

--------------------------------------------
--------------------------------------------
EPOCH: 8
Learning Rate = 0.001000
Loss=0.08850178867578506 Batch_id=468 Accuracy=99.06: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 469/469 [01:02<00:00,  7.49it/s]

Training set: Average loss: 0.0885, Accuracy: 59437/60000 (99.06%)


Test set: Average loss: 0.0196, Accuracy: 9940/10000 (99.40%)

--------------------------------------------
--------------------------------------------
EPOCH: 9
Learning Rate = 0.001000
Loss=0.0026984934229403734 Batch_id=468 Accuracy=99.12: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 469/469 [00:59<00:00,  7.88it/s]

Training set: Average loss: 0.0027, Accuracy: 59474/60000 (99.12%)


Test set: Average loss: 0.0191, Accuracy: 9939/10000 (99.39%)

--------------------------------------------
--------------------------------------------
EPOCH: 10
Learning Rate = 0.001000
Loss=0.06942296773195267 Batch_id=468 Accuracy=99.13: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 469/469 [00:57<00:00,  8.18it/s]

Training set: Average loss: 0.0694, Accuracy: 59476/60000 (99.13%)


Test set: Average loss: 0.0199, Accuracy: 9937/10000 (99.37%)

--------------------------------------------
--------------------------------------------
EPOCH: 11
Learning Rate = 0.001000
Loss=0.016056468710303307 Batch_id=468 Accuracy=99.14: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 469/469 [00:54<00:00,  8.54it/s]

Training set: Average loss: 0.0161, Accuracy: 59487/60000 (99.14%)


Test set: Average loss: 0.0189, Accuracy: 9940/10000 (99.40%)

--------------------------------------------
--------------------------------------------
EPOCH: 12
Learning Rate = 0.001000
Loss=0.029516570270061493 Batch_id=468 Accuracy=99.19: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 469/469 [00:55<00:00,  8.52it/s]

Training set: Average loss: 0.0295, Accuracy: 59511/60000 (99.19%)


Test set: Average loss: 0.0183, Accuracy: 9945/10000 (99.45%)

--------------------------------------------
--------------------------------------------
EPOCH: 13
Learning Rate = 0.001000
Loss=0.05329418182373047 Batch_id=468 Accuracy=99.08: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 469/469 [00:54<00:00,  8.62it/s]

Training set: Average loss: 0.0533, Accuracy: 59447/60000 (99.08%)


Test set: Average loss: 0.0194, Accuracy: 9943/10000 (99.43%)

--------------------------------------------
--------------------------------------------
EPOCH: 14
Learning Rate = 0.001000
Loss=0.07826390862464905 Batch_id=468 Accuracy=99.21: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 469/469 [00:57<00:00,  8.22it/s]

Training set: Average loss: 0.0783, Accuracy: 59524/60000 (99.21%)


Test set: Average loss: 0.0192, Accuracy: 9939/10000 (99.39%)

--------------------------------------------
--------------------------------------------
EPOCH: 15
Learning Rate = 0.001000
Loss=0.007814516313374043 Batch_id=468 Accuracy=99.19: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 469/469 [01:01<00:00,  7.64it/s]

Training set: Average loss: 0.0078, Accuracy: 59515/60000 (99.19%)


Test set: Average loss: 0.0187, Accuracy: 9940/10000 (99.40%)

--------------------------------------------
--------------------------------------------
EPOCH: 16
Learning Rate = 0.000100
Loss=0.0030674831941723824 Batch_id=468 Accuracy=99.19: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 469/469 [01:01<00:00,  7.60it/s]

Training set: Average loss: 0.0031, Accuracy: 59513/60000 (99.19%)


Test set: Average loss: 0.0190, Accuracy: 9941/10000 (99.41%)

--------------------------------------------
--------------------------------------------
EPOCH: 17
Learning Rate = 0.000100
Loss=0.012829647399485111 Batch_id=468 Accuracy=99.26: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 469/469 [01:00<00:00,  7.77it/s]

Training set: Average loss: 0.0128, Accuracy: 59556/60000 (99.26%)


Test set: Average loss: 0.0186, Accuracy: 9941/10000 (99.41%)

--------------------------------------------
--------------------------------------------
EPOCH: 18
Learning Rate = 0.000100
Loss=0.013102131895720959 Batch_id=468 Accuracy=99.21: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 469/469 [00:50<00:00,  9.20it/s]

Training set: Average loss: 0.0131, Accuracy: 59526/60000 (99.21%)


Test set: Average loss: 0.0182, Accuracy: 9949/10000 (99.49%)

--------------------------------------------
--------------------------------------------
EPOCH: 19
Learning Rate = 0.000100
Loss=0.02588658034801483 Batch_id=468 Accuracy=99.23: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 469/469 [00:49<00:00,  9.40it/s]

Training set: Average loss: 0.0259, Accuracy: 59541/60000 (99.23%)


Test set: Average loss: 0.0189, Accuracy: 9944/10000 (99.44%)

--------------------------------------------
```