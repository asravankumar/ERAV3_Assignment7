# ERAV3_Assignment7: model-3 - *final model*


### Model Summary
```
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 10, 26, 26]              90
              ReLU-2           [-1, 10, 26, 26]               0
       BatchNorm2d-3           [-1, 10, 26, 26]              20
           Dropout-4           [-1, 10, 26, 26]               0
            Conv2d-5           [-1, 16, 24, 24]           1,440
              ReLU-6           [-1, 16, 24, 24]               0
       BatchNorm2d-7           [-1, 16, 24, 24]              32
           Dropout-8           [-1, 16, 24, 24]               0
            Conv2d-9            [-1, 8, 22, 22]           1,152
             ReLU-10            [-1, 8, 22, 22]               0
      BatchNorm2d-11            [-1, 8, 22, 22]              16
          Dropout-12            [-1, 8, 22, 22]               0
        MaxPool2d-13            [-1, 8, 11, 11]               0
           Conv2d-14             [-1, 16, 9, 9]           1,152
             ReLU-15             [-1, 16, 9, 9]               0
      BatchNorm2d-16             [-1, 16, 9, 9]              32
          Dropout-17             [-1, 16, 9, 9]               0
           Conv2d-18             [-1, 16, 7, 7]           2,304
             ReLU-19             [-1, 16, 7, 7]               0
      BatchNorm2d-20             [-1, 16, 7, 7]              32
          Dropout-21             [-1, 16, 7, 7]               0
           Conv2d-22             [-1, 10, 5, 5]           1,440
             ReLU-23             [-1, 10, 5, 5]               0
      BatchNorm2d-24             [-1, 10, 5, 5]              20
          Dropout-25             [-1, 10, 5, 5]               0
AdaptiveAvgPool2d-26             [-1, 10, 1, 1]               0
           Conv2d-27             [-1, 10, 1, 1]             100
================================================================
Total params: 7,830
Trainable params: 7,830
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 0.68
Params size (MB): 0.03
Estimated Total Size (MB): 0.72
----------------------------------------------------------------
```

### Model Input Sizes, Output Sizes and Receptive Field Computation
```
# Layer-wise Analysis of the Neural Network
| Layer              | Input Size | Output Size | Input Channels | Output Channels | Kernel Size | Stride | Padding | Receptive Field |
|---------------------|------------|-------------|----------------|-----------------|-------------|--------|---------|----------------|
| Input              | 28x28      | 28x28       | 1              | 1               | -           | -      | -       | 1              |
| Conv1 + ReLU + BN  | 28x28      | 26x26       | 1              | 10              | 3x3         | 1      | 0       | 3              |
| Conv2 + ReLU + BN  | 26x26      | 24x24       | 10             | 16              | 3x3         | 1      | 0       | 5              |
| Conv3 + ReLU + BN  | 24x24      | 22x22       | 16             | 8               | 3x3         | 1      | 0       | 7              |
| MaxPool (Transition1) | 22x22   | 11x11       | 8              | 8               | 2x2         | 2      | 0       | 8              |
| Conv4 + ReLU + BN  | 11x11      | 9x9         | 8              | 16              | 3x3         | 1      | 0       | 12             |
| Conv5 + ReLU + BN  | 9x9        | 7x7         | 16             | 16              | 3x3         | 1      | 0       | 16             |
| Conv6 + ReLU + BN  | 7x7        | 5x5         | 16             | 10              | 3x3         | 1      | 0       | 20             |
| GAP                | 5x5        | 1x1         | 10             | 10              | 5x5         | -      | -       | 28             |
| Conv7              | 1x1        | 1x1         | 10             | 10              | 1x1         | 1      | 0       | 28             |
```


### Target:
  1. Under 8000 parameters and under 15 epochs, consistently reach test accuracy of 99.4% at least three times.

### Results:
  1. Parameters: 7,830
  2. Best Train Accuracy: 99.23% (epoch 15)
  3. Best Test Accuracy: 99.42% (epoch 13)
  4. Reached 99.41% at epoch 12 and the rest of the test accuracies at epoch 13, 14, 15 were 99.42%, 99.41% and 99.41% respectively.

### Analysis:
  1. Upon adding image augmentation, the model was further underfitting now.
  2. Modified the number of channels in each layer multiple times, played with different learning rates but finally found that at almost every network with number of parameters ranging from 7500 to 8000, at epoch 7, 8, 9, 10 it reaches test accuracy of ~99.20 but after that it does not improve significantly.
  3. Finally, used ReduceLROnPlateau scheduler and at epoch 10, the lr got updated and it reached the desired test accuracies(>= 99.40%) consistently.
  4. A scheduler would have yielded the expected result with the previous version of model itself.   



### Training Logs
```
--------------------------------------------
EPOCH: 0
Learning Rate = 0.010000
Loss=0.1989177018404007 Batch_id=468 Accuracy=86.84: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 469/469 [00:39<00:00, 11.82it/s]

Training set: Average loss: 0.1989, Accuracy: 52104/60000 (86.84%)


Test set: Average loss: 0.0799, Accuracy: 9807/10000 (98.07%)

--------------------------------------------
--------------------------------------------
EPOCH: 1
Learning Rate = 0.010000
Loss=0.05726264417171478 Batch_id=468 Accuracy=97.80: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 469/469 [00:40<00:00, 11.61it/s]

Training set: Average loss: 0.0573, Accuracy: 58678/60000 (97.80%)


Test set: Average loss: 0.0462, Accuracy: 9879/10000 (98.79%)

--------------------------------------------
--------------------------------------------
EPOCH: 2
Learning Rate = 0.010000
Loss=0.027088433504104614 Batch_id=468 Accuracy=98.27: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 469/469 [00:41<00:00, 11.37it/s]

Training set: Average loss: 0.0271, Accuracy: 58959/60000 (98.27%)


Test set: Average loss: 0.0380, Accuracy: 9885/10000 (98.85%)

--------------------------------------------
--------------------------------------------
EPOCH: 3
Learning Rate = 0.010000
Loss=0.028176499530673027 Batch_id=468 Accuracy=98.48: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 469/469 [00:40<00:00, 11.60it/s]

Training set: Average loss: 0.0282, Accuracy: 59088/60000 (98.48%)


Test set: Average loss: 0.0293, Accuracy: 9910/10000 (99.10%)

--------------------------------------------
--------------------------------------------
EPOCH: 4
Learning Rate = 0.010000
Loss=0.08518072962760925 Batch_id=468 Accuracy=98.58: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 469/469 [00:40<00:00, 11.65it/s]

Training set: Average loss: 0.0852, Accuracy: 59148/60000 (98.58%)


Test set: Average loss: 0.0316, Accuracy: 9911/10000 (99.11%)

--------------------------------------------
--------------------------------------------
EPOCH: 5
Learning Rate = 0.010000
Loss=0.012765870429575443 Batch_id=468 Accuracy=98.65: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 469/469 [00:41<00:00, 11.41it/s]

Training set: Average loss: 0.0128, Accuracy: 59192/60000 (98.65%)


Test set: Average loss: 0.0264, Accuracy: 9924/10000 (99.24%)

--------------------------------------------
--------------------------------------------
EPOCH: 6
Learning Rate = 0.010000
Loss=0.012400330044329166 Batch_id=468 Accuracy=98.81: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 469/469 [00:43<00:00, 10.89it/s]

Training set: Average loss: 0.0124, Accuracy: 59285/60000 (98.81%)


Test set: Average loss: 0.0228, Accuracy: 9933/10000 (99.33%)

--------------------------------------------
--------------------------------------------
EPOCH: 7
Learning Rate = 0.010000
Loss=0.05124722421169281 Batch_id=468 Accuracy=98.89: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 469/469 [00:42<00:00, 10.91it/s]

Training set: Average loss: 0.0512, Accuracy: 59332/60000 (98.89%)


Test set: Average loss: 0.0236, Accuracy: 9932/10000 (99.32%)

--------------------------------------------
--------------------------------------------
EPOCH: 8
Learning Rate = 0.010000
Loss=0.10265680402517319 Batch_id=468 Accuracy=98.84: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 469/469 [00:40<00:00, 11.44it/s]

Training set: Average loss: 0.1027, Accuracy: 59304/60000 (98.84%)


Test set: Average loss: 0.0236, Accuracy: 9922/10000 (99.22%)

--------------------------------------------
--------------------------------------------
EPOCH: 9
Learning Rate = 0.001000
Loss=0.00252863229252398 Batch_id=468 Accuracy=99.11: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 469/469 [00:40<00:00, 11.44it/s]

Training set: Average loss: 0.0025, Accuracy: 59468/60000 (99.11%)


Test set: Average loss: 0.0192, Accuracy: 9936/10000 (99.36%)

--------------------------------------------
--------------------------------------------
EPOCH: 10
Learning Rate = 0.001000
Loss=0.06702481955289841 Batch_id=468 Accuracy=99.14: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 469/469 [00:42<00:00, 10.95it/s]

Training set: Average loss: 0.0670, Accuracy: 59484/60000 (99.14%)


Test set: Average loss: 0.0196, Accuracy: 9934/10000 (99.34%)

--------------------------------------------
--------------------------------------------
EPOCH: 11
Learning Rate = 0.001000
Loss=0.013927728869020939 Batch_id=468 Accuracy=99.15: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 469/469 [00:41<00:00, 11.18it/s]

Training set: Average loss: 0.0139, Accuracy: 59491/60000 (99.15%)


Test set: Average loss: 0.0189, Accuracy: 9941/10000 (99.41%)

--------------------------------------------
--------------------------------------------
EPOCH: 12
Learning Rate = 0.001000
Loss=0.030060604214668274 Batch_id=468 Accuracy=99.17: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 469/469 [00:40<00:00, 11.47it/s]

Training set: Average loss: 0.0301, Accuracy: 59499/60000 (99.17%)


Test set: Average loss: 0.0179, Accuracy: 9942/10000 (99.42%)

--------------------------------------------
--------------------------------------------
EPOCH: 13
Learning Rate = 0.001000
Loss=0.05117041990160942 Batch_id=468 Accuracy=99.12: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 469/469 [00:40<00:00, 11.52it/s]

Training set: Average loss: 0.0512, Accuracy: 59475/60000 (99.12%)


Test set: Average loss: 0.0189, Accuracy: 9941/10000 (99.41%)

--------------------------------------------
--------------------------------------------
EPOCH: 14
Learning Rate = 0.001000
Loss=0.05837203562259674 Batch_id=468 Accuracy=99.23: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 469/469 [00:41<00:00, 11.26it/s]

Training set: Average loss: 0.0584, Accuracy: 59538/60000 (99.23%)


Test set: Average loss: 0.0187, Accuracy: 9941/10000 (99.41%)

--------------------------------------------
--------------------------------------------
EPOCH: 15
Learning Rate = 0.000100
Loss=0.008865851908922195 Batch_id=468 Accuracy=99.22: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 469/469 [00:40<00:00, 11.54it/s]

Training set: Average loss: 0.0089, Accuracy: 59533/60000 (99.22%)


Test set: Average loss: 0.0182, Accuracy: 9940/10000 (99.40%)

--------------------------------------------
--------------------------------------------
EPOCH: 16
Learning Rate = 0.000100
Loss=0.0028003647457808256 Batch_id=468 Accuracy=99.18: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 469/469 [00:43<00:00, 10.81it/s]

Training set: Average loss: 0.0028, Accuracy: 59506/60000 (99.18%)


Test set: Average loss: 0.0186, Accuracy: 9944/10000 (99.44%)

--------------------------------------------
--------------------------------------------
EPOCH: 17
Learning Rate = 0.000010
Loss=0.013447102159261703 Batch_id=468 Accuracy=99.27: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 469/469 [00:43<00:00, 10.78it/s]

Training set: Average loss: 0.0134, Accuracy: 59560/60000 (99.27%)


Test set: Average loss: 0.0183, Accuracy: 9942/10000 (99.42%)

--------------------------------------------
--------------------------------------------
EPOCH: 18
Learning Rate = 0.000010
Loss=0.010827328078448772 Batch_id=468 Accuracy=99.23: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 469/469 [00:46<00:00, 10.18it/s]

Training set: Average loss: 0.0108, Accuracy: 59540/60000 (99.23%)


Test set: Average loss: 0.0180, Accuracy: 9945/10000 (99.45%)

--------------------------------------------
--------------------------------------------
EPOCH: 19
Learning Rate = 0.000001
Loss=0.023541582748293877 Batch_id=468 Accuracy=99.24: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 469/469 [00:53<00:00,  8.80it/s]

Training set: Average loss: 0.0235, Accuracy: 59543/60000 (99.24%)


Test set: Average loss: 0.0186, Accuracy: 9939/10000 (99.39%)

--------------------------------------------
```